import gymnasium as gym
import numpy as np
import matplotlib.pyplot as plt
import pickle
import os

# --- æœ€çµ‚åƒæ•¸ (å¯¦é©— 7 é…ç½®: High Stability) ---
LEARNING_RATE = 0.05      # ä½å­¸ç¿’ç‡ (ç©©å®š)
DISCOUNT_FACTOR = 0.99    # æ¨™æº–é è¦‹
PENALTY = -0.8           # é‡è™•ç½° (è¬¹æ…) 
PBRS_SCALE = 2.2          # [é—œéµ] å¼·å°èˆªè¨Šè™Ÿ (å› ç‚ºæœ‰ä½ LR ä¿è­·ï¼Œæ‰€ä»¥é–‹å¤§ä¸€é»æ²’é—œä¿‚)
EPSILON_DECAY = 0.0000025
MIN_EPSILON = 0.001

def random_argmax(q_values):
    """è§£æ±º np.argmax åå·®çš„é—œéµå‡½å¼"""
    top_value = np.max(q_values)
    ties = np.flatnonzero(q_values == top_value)
    return np.random.choice(ties)

def get_potential(state):
    """PBRS ä½èƒ½è¨ˆç®—"""
    row = state // 8
    col = state % 8
    goal_row, goal_col = 7, 7
    dist = abs(goal_row - row) + abs(goal_col - col)
    max_dist = 14
    return (max_dist - dist) / max_dist

def train_one_round(episode_count, run_id):
    """åŸ·è¡Œä¸€æ¬¡å®Œæ•´çš„è¨“ç·´"""
    env = gym.make('FrozenLake-v1', map_name="8x8", is_slippery=True)
    
    # éš¨æ©Ÿåˆå§‹åŒ–
    q = np.random.uniform(low=0, high=0.001, size=(env.observation_space.n, env.action_space.n))
    
    rng = np.random.default_rng()
    rewards_per_episode = np.zeros(episode_count)
    epsilon = 1.0
    
    for i in range(episode_count):
        state = env.reset()[0]
        terminated = False
        truncated = False
        current_potential = get_potential(state)

        while not terminated and not truncated:
            if rng.random() < epsilon:
                action = env.action_space.sample()
            else:
                action = random_argmax(q[state, :])

            new_state, reward, terminated, truncated, _ = env.step(action)
            next_potential = get_potential(new_state)

            # PBRS (Scale 2.0) + Penalty (-0.75)
            shaping = PBRS_SCALE * (DISCOUNT_FACTOR * next_potential - current_potential)
            modified_reward = reward
            if terminated and reward == 0:
                modified_reward = PENALTY
            
            total_reward = modified_reward + shaping

            q[state, action] = q[state, action] + LEARNING_RATE * (
                total_reward + DISCOUNT_FACTOR * np.max(q[new_state, :]) - q[state, action]
            )

            state = new_state
            current_potential = next_potential
            
            epsilon = max(epsilon - EPSILON_DECAY, MIN_EPSILON)

        if reward == 1:
            rewards_per_episode[i] = 1

    env.close()
    return q, rewards_per_episode

def evaluate(q_table, eval_episodes=1000):
    """è©•ä¼°ç›®å‰çš„ Q-Table"""
    env = gym.make('FrozenLake-v1', map_name="8x8", is_slippery=True)
    success_count = 0
    
    for _ in range(eval_episodes):
        state = env.reset()[0]
        terminated = False
        truncated = False
        
        while not terminated and not truncated:
            # è©•ä¼°æ™‚å®Œå…¨ä¸æ¢ç´¢ (Greedy)
            action = random_argmax(q_table[state, :])
            state, reward, terminated, truncated, _ = env.step(action)
            
            if reward == 1:
                success_count += 1
                
    env.close()
    return (success_count / eval_episodes) * 100

if __name__ == '__main__':
    TOTAL_RUNS = 10        # é€£çºŒè·‘ 10 æ¬¡åˆ·åˆ†
    TRAIN_EPISODES = 15000 
    
    best_success_rate = 0.0
    best_run_id = -1
    
    print(f"ğŸ”¥ é–‹å§‹è‡ªå‹•åˆ·åˆ† (Scale 2.2 ç‰ˆ)...")
    print("-" * 40)

    for i in range(1, TOTAL_RUNS + 1):
        print(f"ğŸ”„ Round {i}/{TOTAL_RUNS}: Training...", end="\r")
        
        # 1. è¨“ç·´
        q_table, train_rewards = train_one_round(TRAIN_EPISODES, i)
        
        # 2. è©•ä¼°
        score = evaluate(q_table)
        print(f"ğŸ“Š Round {i}/{TOTAL_RUNS}: Success Rate = {score:.2f}%", end="")
        
        # 3. ç´€éŒ„æœ€é«˜åˆ†
        if score > best_success_rate:
            best_success_rate = score
            best_run_id = i
            print("  (â­ New Best!)")
            
            # å­˜æª”
            with open('frozen_lake8x8_best.pkl', 'wb') as f:
                pickle.dump(q_table, f)
            
            # ç•«åœ–
            plt.clf()
            sum_rewards = np.zeros(TRAIN_EPISODES)
            for t in range(TRAIN_EPISODES):
                sum_rewards[t] = np.sum(train_rewards[max(0, t-100):(t+1)])
            plt.plot(sum_rewards)
            plt.title(f'Best Run (Score: {score:.2f}%)')
            plt.savefig('frozen_lake8x8_best.png')
            
        else:
            print("") 

    print("-" * 40)
    print(f"ğŸ† æœ€çµ‚çµæœï¼šæœ€é«˜åˆ†å‡ºç¾åœ¨ç¬¬ {best_run_id} è¼ª")
    print(f"âœ… Final Best Success Rate: {best_success_rate:.2f}%")
